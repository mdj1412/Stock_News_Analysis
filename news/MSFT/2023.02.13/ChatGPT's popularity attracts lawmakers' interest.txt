Created by OpenAI, a private company backed by Microsoft, ChatGPT was estimated to have reached 100 million monthly active users just two months after launch, making it the fastest-growing consumer application in history.But its popularity has also made it a fast-growing target for regulation, attracting the attention of U.S. lawmakers with questions about its impact on education and national security. Representative Ted Lieu, a Democrat on the House of Representatives Science Committee, said that while he was excited about the chatbot, he was also "freaked out by A.I., specifically A.I. that is left unchecked and unregulated."Democratic senator Ron Wyden, according to an aide, emphasized the need to make sure AI did not include biases that would lead to discrimination in the real world, like with housing or jobs.  One law firm focused on AI liability pointed to the national security concerns, warning "malicious actors, non-state actors and state actors that have interests that are adversarial to the United States to be using these systems to generate information that could be wrong or could be harmful."  At this point, much of the recent concern around ChatGPT has come mainly from educators focused on cheating and plagiarism.Others have voiced concerns that the computer program could also be used to spread disinformation. In a statement, OpenAI said: "We don't want ChatGPT to be used for misleading purposes in schools or anywhere else, so we're already developing mitigations to help anyone identify text generated by that system."  ChatGPT itself demurred when asked how it should be regulated, saying: "As a neutral AI language model, I don't have a stance on specific laws that may or may not be enacted to regulate AI systems like me." But it then went on to list potential areas of focus for regulators, such as data privacy, bias and fairness, and transparency in how answers are written.